{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "from typing import Union, List\n",
    "import pandas as pd\n",
    "from MyDataSet import MultiMaskTimeSeriesDataset\n",
    "\n",
    "def graph_counter(adj):\n",
    "    n=len(adj)\n",
    "    visited=[0]*n\n",
    "    \n",
    "    num_of_graph=0\n",
    "    count=0\n",
    "    while 1:\n",
    "        # stack=[0]\n",
    "        flag=0\n",
    "        for i in range(n):\n",
    "            if visited[i]==0:\n",
    "                stack=[i]\n",
    "                visited[i]=1\n",
    "                flag=1\n",
    "                break\n",
    "        \n",
    "        if flag==0:\n",
    "            break    \n",
    "        \n",
    "        count = 1\n",
    "        while stack:\n",
    "            node=stack.pop()\n",
    "            for i in range(n):\n",
    "                if adj[node][i]==1 and visited[i]==0:\n",
    "                    visited[i]=1\n",
    "                    stack.append(i)\n",
    "                    count+=1\n",
    "        num_of_graph+=1\n",
    "        print('num of nodes:',count)\n",
    "        \n",
    "    return num_of_graph\n",
    "def get_adjacency_matrix(distance_df_filename: str, num_of_vertices: int, id_filename: str = None) -> tuple:\n",
    "    \"\"\"Generate adjacency matrix.\n",
    "\n",
    "    Args:\n",
    "        distance_df_filename (str): path of the csv file contains edges information\n",
    "        num_of_vertices (int): number of vertices\n",
    "        id_filename (str, optional): id filename. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        tuple: two adjacency matrix.\n",
    "            np.array: connectivity-based adjacency matrix A (A[i, j]=0 or A[i, j]=1)\n",
    "            np.array: distance-based adjacency matrix A\n",
    "    \"\"\"\n",
    "\n",
    "    if \"npy\" in distance_df_filename:\n",
    "        adj_mx = np.load(distance_df_filename)\n",
    "        return adj_mx, None\n",
    "    else:\n",
    "        adjacency_matrix_connectivity = np.zeros((int(num_of_vertices), int(\n",
    "            num_of_vertices)), dtype=np.float32)\n",
    "        adjacency_matrix_distance = np.zeros((int(num_of_vertices), int(num_of_vertices)),\n",
    "                                             dtype=np.float32)\n",
    "        if id_filename:\n",
    "            # the id in the distance file does not start from 0, so it needs to be remapped\n",
    "            with open(id_filename, \"r\") as f:\n",
    "                id_dict = {int(i): idx for idx, i in enumerate(\n",
    "                    f.read().strip().split(\"\\n\"))}  # map node idx to 0-based index (start from 0)\n",
    "            with open(distance_df_filename, \"r\") as f:\n",
    "                f.readline()  # omit the first line\n",
    "                reader = csv.reader(f)\n",
    "                for row in reader:\n",
    "                    if len(row) != 3:\n",
    "                        continue\n",
    "                    i, j, distance = int(row[0]), int(row[1]), float(row[2])\n",
    "                    adjacency_matrix_connectivity[id_dict[i], id_dict[j]] = 1\n",
    "                    adjacency_matrix_connectivity[id_dict[j], id_dict[i]] = 1\n",
    "                    adjacency_matrix_distance[id_dict[i],\n",
    "                                              id_dict[j]] = distance\n",
    "                    adjacency_matrix_distance[id_dict[j],\n",
    "                                              id_dict[i]] = distance\n",
    "            return adjacency_matrix_connectivity, adjacency_matrix_distance\n",
    "        else:\n",
    "            data=pd.read_csv(distance_df_filename)\n",
    "\n",
    "            for index, row in data.iterrows():\n",
    "                i, j, distance = int(row['from']), int(row['to']), float(row['cost'])\n",
    "                adjacency_matrix_connectivity[i, j] = 1\n",
    "                adjacency_matrix_connectivity[j, i] = 1\n",
    "                adjacency_matrix_distance[i, j] = distance\n",
    "                adjacency_matrix_distance[j, i] = distance\n",
    "            return adjacency_matrix_connectivity, adjacency_matrix_distance\n",
    "def time_unit_to_nanoseconds(time_unit: str):\n",
    "    # check_time_unit(time_unit)\n",
    "    if time_unit == 'year':\n",
    "        return 365.2425 * 24 * 60 * 60 * 10**9\n",
    "    elif time_unit == 'week':\n",
    "        time_unit = 'W'\n",
    "    return pd.Timedelta('1' + time_unit).value\n",
    "\n",
    "def datetime_encoded(dataset : pd.DataFrame, units: Union[str, List]) -> pd.DataFrame:\n",
    "    r\"\"\"Transform dataset's temporal index into covariates using sinusoidal\n",
    "    transformations. Each temporal unit is used as period to compute the\n",
    "    operations, obtaining two feature (:math:`\\sin` and :math:`\\cos`) for\n",
    "    each unit.\"\"\"\n",
    "\n",
    "    datetime = dict()\n",
    "    for unit in units:\n",
    "        nano_unit = time_unit_to_nanoseconds(unit)\n",
    "        nano_sec =  dataset[unit]* (2 * np.pi / nano_unit)\n",
    "        datetime[unit + '_sin'] = np.sin(nano_sec)\n",
    "        datetime[unit + '_cos'] = np.cos(nano_sec)\n",
    "    return pd.DataFrame(datetime, dtype=np.float32)\n",
    "\n",
    "df = pd.DataFrame({'time': pd.date_range('2020-01-01', periods=288, freq='5min')})\n",
    "df['day']=df['time'].dt.time\n",
    "df['day']=df['day'].apply(lambda x: (x.hour*3600+x.minute*60+x.second)*10**9)\n",
    "dateencoded=datetime_encoded(df, ['day'])\n",
    "print(dateencoded.shape)\n",
    "\n",
    "file_path=r'D:\\WorkPath\\Models\\ImputeFormer\\Data\\raw_data\\METR-LA\\node_values.npy'\n",
    "\n",
    "data=np.load(file_path)\n",
    "num_of_vertices = data.shape[1]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from turtle import distance\n",
    "sys.path\n",
    "\n",
    "adj_path=r'D:\\WorkPath\\Models\\ImputeFormer\\Data\\raw_data\\METR-LA\\adj_mat.npy'\n",
    "adj,distance= get_adjacency_matrix(adj_path,num_of_vertices,None)\n",
    "\n",
    "graph_counter(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k={}\n",
    "for head_ in range(0,207):\n",
    "    road=[head_]\n",
    "    head=head_\n",
    "    for i in range(100):\n",
    "        for j in range(num_of_vertices):\n",
    "            if adj[head][j] > 0.1 and j not in road :\n",
    "                road.append(j)\n",
    "                head = j\n",
    "                break\n",
    "    # print(len(road))\n",
    "    k[head_]=len(road)    \n",
    "    # print(road)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road=[102]\n",
    "head=102\n",
    "for i in range(100):\n",
    "    for j in range(num_of_vertices):\n",
    "        if adj[head][j] > 0.01 and j not in road :\n",
    "            road.append(j)\n",
    "            head = j\n",
    "            break\n",
    "print(len(road))    \n",
    "print(road)\n",
    "\n",
    "road = [6 ,91, 15, 33, 93, 136, 17, 12, 80, 128, 94, 74, 72, 69, 47, 52, 73, 70, 98, 96, 97, 127, 154, 155, 157, 159, 160, 161, 162, 163, 187, 188, 198, 206]          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_matrix=data[:12*24*2,road,0]\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.imshow(speed_matrix.T,aspect='auto',cmap='jet',origin='lower')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "route = '006'\n",
    "direction = 'N'\n",
    "route_start = 0\n",
    "route_len =32\n",
    "missing_rate = 0.3\n",
    "missing_type = ['random','linear','block','mixed']\n",
    "missing_type_ind = 0\n",
    "num_masks = 40\n",
    "data_type=['source_train','source_test','target_train','target_test']\n",
    "data_type_ind = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_matrix= data[:,road,0]\n",
    "hot_map_data=speed_matrix.reshape(-1,288,len(road))\n",
    "hot_map_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = hot_map_data>1.0\n",
    "data = speed_matrix.reshape(-1,288,len(road))\n",
    "for i in range(data.shape[0]):\n",
    "    for j in range(data.shape[1]):\n",
    "        for k in range(data.shape[2]):\n",
    "            if mask[i, j, k] == 0:\n",
    "                if i == 0:\n",
    "                    hot_map_data[i, j, k] = data[i+ 1, j, k ]\n",
    "                elif i == data.shape[0] - 1:\n",
    "                    hot_map_data[i, j, k] = data[i - 1, j, k]\n",
    "                else:\n",
    "                    hot_map_data[i, j, k] = (data[i - 1, j, k] + data[i+ 1, j, k ]) / 2\n",
    "hot_map_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "test_ratio = 0.2\n",
    "source_train_data = hot_map_data[:int(hot_map_data.shape[0]*train_ratio)]\n",
    "test_data = hot_map_data[int(hot_map_data.shape[0]*train_ratio):int(hot_map_data.shape[0]*(train_ratio+test_ratio))]\n",
    "target_train_data = hot_map_data[int(hot_map_data.shape[0]*(train_ratio+test_ratio)):]\n",
    "print(source_train_data.shape,test_data.shape,target_train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir=r'D:\\WorkPath\\Models\\ImputeFormer\\Data\\source_test_METRLA'\n",
    "train_dir=r'D:\\WorkPath\\Models\\ImputeFormer\\Data\\source_train_METRLA'\n",
    "# os.makedirs(train_dir)\n",
    "# os.makedirs(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "test_ratio = 0.2\n",
    "missing_rate = 0.3\n",
    "x = list(range( int(hot_map_data.shape[0])  ))\n",
    "random.shuffle(x)\n",
    "\n",
    "for missing_type_ind in range(4):\n",
    "    for route_start in range(0,2,5):\n",
    "        for time_start in [7,11,15,19]:\n",
    "            \n",
    "            save_path = train_dir\n",
    "            save_path_test = test_dir\n",
    "\n",
    "            # save_path=os.path.join(r'D:\\WorkPath\\Models\\ImputeFormer\\Data',data_type[data_type_ind])+'_METRLA'\n",
    "            # save_path_test=os.path.join(r'D:\\WorkPath\\Models\\ImputeFormer\\Data',data_type[data_type_ind+1])+'_METRLA'\n",
    "\n",
    "\n",
    "            \n",
    "            # dataset = MultiMaskTimeSeriesDataset(hot_map_data[ x[0:int(train_ratio* hot_map_data.shape[0]) ],\n",
    "            #                                     time_start*12:(time_start+4)*12,  route_start:route_start+route_len  ],\n",
    "            #                                      dateencoded.values[time_start*12:(time_start+4)*12,:],\n",
    "            #                                     missing_rate, missing_type[missing_type_ind], num_masks)\n",
    "            # dataset_file = os.path.join(save_path, \n",
    "            #                             'METR_LA_speed_{}-{}_{}_{}_{}.pkl'.format\n",
    "            #                             (route, time_start ,route_start ,int(missing_rate*100) , missing_type[missing_type_ind]))\n",
    "            # pd.to_pickle(dataset, dataset_file)\n",
    "            \n",
    "            dataset = MultiMaskTimeSeriesDataset(hot_map_data[ x[int(train_ratio* hot_map_data.shape[0]): ],\n",
    "                                                time_start*12:(time_start+4)*12,route_start:route_start+route_len],\n",
    "                                                 dateencoded.values[time_start*12:(time_start+4)*12,:],\n",
    "                                                missing_rate, missing_type[missing_type_ind], 5)\n",
    "            dataset_file = os.path.join(save_path_test, \n",
    "                                        'METR_LA_speed_{}-{}_{}_{}_{}.pkl'.format\n",
    "                                        (route, time_start ,route_start ,int(missing_rate*100) , missing_type[missing_type_ind]))\n",
    "            pd.to_pickle(dataset, dataset_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
