{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import hot\n",
    "import pandas as pd\n",
    "import typing\n",
    "import os \n",
    "import random\n",
    "import pickle\n",
    "import torch\n",
    "from typing import Union, List\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from MyDataSet import MultiMaskTimeSeriesDataset\n",
    "\n",
    "project_path = r'D:\\WorkPath\\Models\\ImputeFormer\\Data'\n",
    "\n",
    "free_flow_file=project_path+r'\\raw_data\\Seattle\\Loop_Seattle_2015_reachability_free_flow_5min.npy'\n",
    "data_file=project_path+r'\\raw_data\\Seattle\\speed_matrix_2015'\n",
    "\n",
    "raw_data=pd.read_pickle(data_file)\n",
    "raw_data.index=pd.to_datetime(raw_data.index)\n",
    "\n",
    "node_files=project_path+r'\\raw_data\\Seattle\\nodes_loop_mp_list.csv'\n",
    "node=pd.read_csv(node_files,header=0,index_col=0)\n",
    "node['direction']=node['milepost'].apply(lambda x: x[0])\n",
    "node['route']=node['milepost'].apply(lambda x: x[1:4])\n",
    "node['mile_post']=node['milepost'].apply(lambda x: float(x[6:]))\n",
    "\n",
    "node.groupby(['direction','route']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.index=pd.to_datetime(raw_data.index)\n",
    "raw_data['day']=raw_data.index.time\n",
    "raw_data['day']=raw_data['day'].apply(lambda x: (x.hour*3600+x.minute*60+x.second)*10**9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_unit_to_nanoseconds(time_unit: str):\n",
    "    # check_time_unit(time_unit)\n",
    "    if time_unit == 'year':\n",
    "        return 365.2425 * 24 * 60 * 60 * 10**9\n",
    "    elif time_unit == 'week':\n",
    "        time_unit = 'W'\n",
    "    return pd.Timedelta('1' + time_unit).value\n",
    "\n",
    "def datetime_encoded(dataset : pd.DataFrame, units: Union[str, List]) -> pd.DataFrame:\n",
    "    r\"\"\"Transform dataset's temporal index into covariates using sinusoidal\n",
    "    transformations. Each temporal unit is used as period to compute the\n",
    "    operations, obtaining two feature (:math:`\\sin` and :math:`\\cos`) for\n",
    "    each unit.\"\"\"\n",
    "\n",
    "    datetime = dict()\n",
    "    for unit in units:\n",
    "        nano_unit = time_unit_to_nanoseconds(unit)\n",
    "        nano_sec =  dataset[unit]* (2 * np.pi / nano_unit)\n",
    "        datetime[unit + '_sin'] = np.sin(nano_sec)\n",
    "        datetime[unit + '_cos'] = np.cos(nano_sec)\n",
    "    return pd.DataFrame(datetime, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateencoded=datetime_encoded(raw_data, ['day'])\n",
    "dateencoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route = '005'\n",
    "direction = 'i'\n",
    "route_start = 0\n",
    "route_len =32\n",
    "missing_rate = 0.3\n",
    "missing_type = ['random','linear','block','mixed']\n",
    "missing_type_ind = 2\n",
    "num_masks = 10\n",
    "data_type=['source_train','source_test','target_train','target_test']\n",
    "data_type_ind = 0\n",
    "\n",
    "if direction=='i':\n",
    "    route1=node.query('route==@route and direction==@direction').sort_values('mile_post',ascending=False)['milepost']\n",
    "else:\n",
    "    route1=node.query('route==@route and direction==@direction').sort_values('mile_post',ascending=True)['milepost']\n",
    "hot_map_data = raw_data.loc[:][route1]\n",
    "\n",
    "\n",
    "hot_map_data=hot_map_data.values\n",
    "hot_map_data=hot_map_data.reshape(-1,288,hot_map_data.shape[-1])\n",
    "hot_map_data.shape\n",
    "\n",
    "np.random.shuffle(hot_map_data)\n",
    "\n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.2\n",
    "source_train_data = hot_map_data[:int(hot_map_data.shape[0]*train_ratio)]\n",
    "test_data = hot_map_data[int(hot_map_data.shape[0]*train_ratio):int(hot_map_data.shape[0]*(train_ratio+test_ratio))]\n",
    "target_train_data = hot_map_data[int(hot_map_data.shape[0]*(train_ratio+test_ratio)):]\n",
    "print(source_train_data.shape,test_data.shape,target_train_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(20, 10))\n",
    "hot_map = ax.imshow(hot_map_data[6,:,:].T, cmap='jet', interpolation='nearest')\n",
    "plt.colorbar(hot_map)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir=r'D:\\WorkPath\\Models\\ImputeFormer\\Data\\source_test_Seattle'\n",
    "train_dir=r'D:\\WorkPath\\Models\\ImputeFormer\\Data\\source_train_Seattle'\n",
    "# os.makedirs(train_dir)\n",
    "# os.makedirs(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "test_ratio = 0.2\n",
    "missing_rate = 0.7\n",
    "\n",
    "random.seed(0)\n",
    "x = list(range( hot_map_data.shape[0] ))\n",
    "random.shuffle(x)\n",
    "\n",
    "# for missing_type_ind in range(4):\n",
    "for missing_type_ind in [3]:\n",
    "    for route_start in range(0,64-32,6):\n",
    "        for time_start in [7,11,15,19]:\n",
    "            \n",
    "            save_path = train_dir\n",
    "            save_path_test = test_dir\n",
    "\n",
    "            \n",
    "\n",
    "            # dataset = MultiMaskTimeSeriesDataset(hot_map_data[ 5:7,\n",
    "            #                                     time_start*12:(time_start+4)*12,route_start:route_start+route_len],\n",
    "            #                                      dateencoded.values[time_start*12:(time_start+4)*12,:],\n",
    "            #                                     missing_rate, missing_type[missing_type_ind], num_masks)\n",
    "            # dataset_file = os.path.join(r'D:\\WorkPath\\Models\\Plot\\Seattle405', \n",
    "            #                             'Seattle_405_speed_{}-{}_{}_{}_{}.pkl'.format\n",
    "            #                             (route, time_start ,route_start ,int(missing_rate*100) , missing_type[missing_type_ind]))\n",
    "            # pd.to_pickle(dataset, dataset_file)\n",
    "            \n",
    "\n",
    "            # dataset = MultiMaskTimeSeriesDataset(hot_map_data[ x[0:int(train_ratio* hot_map_data.shape[0]) ],\n",
    "            #                                     time_start*12:(time_start+4)*12,route_start:route_start+route_len],\n",
    "            #                                      dateencoded.values[time_start*12:(time_start+4)*12,:],\n",
    "            #                                     missing_rate, missing_type[missing_type_ind], num_masks)\n",
    "\n",
    "            # dataset_file = os.path.join(save_path, \n",
    "            #                             'Seattle_405_speed_{}{}_{}_{}_{}.pkl'.format\n",
    "            #                             (route, time_start ,route_start ,int(missing_rate*100) , missing_type[missing_type_ind]))\n",
    "            # pd.to_pickle(dataset, dataset_file)\n",
    "            \n",
    "            dataset = MultiMaskTimeSeriesDataset(hot_map_data[ x[int(train_ratio* hot_map_data.shape[0]): ],\n",
    "                                                time_start*12:(time_start+4)*12,route_start:route_start+route_len],\n",
    "                                                 dateencoded.values[time_start*12:(time_start+4)*12,:],\n",
    "                                                missing_rate, missing_type[missing_type_ind], 5)\n",
    "            # 保存数据集\n",
    "            dataset_file = os.path.join(save_path_test, \n",
    "                                        'Seattle_2015_speed_{}{}_{}_{}_{}.pkl'.format\n",
    "                                        (route, time_start ,route_start ,int(missing_rate*100) , missing_type[missing_type_ind]))\n",
    "            pd.to_pickle(dataset, dataset_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepGAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
